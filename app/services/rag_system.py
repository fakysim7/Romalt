import asyncio
from typing import List, Dict
from services.web_search import WebSearch
import logging
import re
import hashlib
from datetime import datetime

logger = logging.getLogger(__name__)

class RAGSystem:
    def __init__(self, always_enabled: bool = True):
        self.web_search = WebSearch()
        self.context_window = 4000
        self.always_enabled = always_enabled
        self.cache = {}  # ÐºÑÑˆ

    def _cache_key(self, query: str):
        return hashlib.md5(query.encode('utf-8')).hexdigest()

    async def get_relevant_context(self, query: str) -> str:
        """Ð’ÑÐµÐ³Ð´Ð° Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚"""
        try:
            current_year = datetime.now().year
            search_query = self._build_search_query(query) + f" {current_year}"
            results = await self.web_search.search_and_extract(search_query, num_results=5)
            context = self._format_context(results, query)
            return context
        except Exception as e:
            logger.error(f"RAG error: {e}")
            return f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {query}"

    def _build_search_query(self, original_query: str) -> str:
        stop_words = {'ÐºÐ°Ðº', 'Ñ‡Ñ‚Ð¾', 'Ð³Ð´Ðµ', 'ÐºÐ¾Ð³Ð´Ð°', 'Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ', 'Ð·Ð°Ñ‡ÐµÐ¼', 'Ð¼Ð½Ðµ', 'Ñ‚Ñ‹', 'Ð²Ñ‹', 'ÑÐ²Ð¾Ð¹'}
        words = original_query.lower().split()
        filtered = [w for w in words if w not in stop_words and len(w) > 2]
        if filtered:
            return ' '.join(filtered) + ' Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ'
        return original_query + ' Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ'

    def _format_context(self, results: List[Dict], original_query: str) -> str:
        if not results:
            return f"ÐŸÐ¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ '{original_query}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸."
        parts = [f"ðŸ” Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ð¾ '{original_query}':", "="*50]
        valid = 0
        for i, r in enumerate(results, 1):
            if r['content'] and len(r['content']) > 50:
                domain = self._extract_domain(r['url'])
                parts.append(f"Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº {i} | {domain}:\n{self._clean_content(r['content'])}")
                parts.append("-"*40)
                valid += 1
        if valid == 0:
            return f"ÐŸÐ¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ '{original_query}' Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¼Ð°Ð»Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸."
        parts.append(f"Ð’ÑÐµÐ³Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²: {valid}")
        full = "\n".join(parts)
        return full[:self.context_window] + ("\n[...Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ€ÐµÐ·Ð°Ð½Ð°...]" if len(full) > self.context_window else "")

    def _extract_domain(self, url: str) -> str:
        from urllib.parse import urlparse
        return urlparse(url).netloc.replace('www.', '')

    def _clean_content(self, content: str) -> str:
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð¸ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÑ‹
        content = re.sub(r'\s+', ' ', content)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ markdown-Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ###, ##, #
        content = re.sub(r'#{1,6}\s*', '', content)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹/ÐºÑƒÑ€ÑÐ¸Ð²Ð½Ñ‹Ð¹ (**Ñ‚ÐµÐºÑÑ‚**, *Ñ‚ÐµÐºÑÑ‚*, _Ñ‚ÐµÐºÑÑ‚_, __Ñ‚ÐµÐºÑÑ‚__)
        content = re.sub(r'(\*\*|__)(.*?)\1', r'\2', content)  # Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹
        content = re.sub(r'(\*|_)(.*?)\1', r'\2', content)     # ÐºÑƒÑ€ÑÐ¸Ð²
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ ÑÑÑ‹Ð»ÐºÐ¸ [Ñ‚ÐµÐºÑÑ‚](url)
        content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1', content)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ²Ð½Ñ‹Ðµ http/https ÑÑÑ‹Ð»ÐºÐ¸
        content = re.sub(r'https?://\S+', '', content)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼Ð°Ñ€ÐºÐµÑ€Ñ‹ ÑÐ¿Ð¸ÑÐºÐ¾Ð² (-, *, â€¢, >)
        content = re.sub(r'^[\s>*â€¢-]+', '', content, flags=re.MULTILINE)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸ÐµÑÑ Ð´ÐµÑ„Ð¸ÑÑ‹/Ñ€Ð°Ð²ÐµÐ½ÑÑ‚Ð²Ð° (---, ===)
        content = re.sub(r'[-=]{3,}', ' ', content)
        # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ markdown-ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ (Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¸ `~`, `>`, '`')
        content = re.sub(r'[~`>]', '', content)
        # Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð²
        content = re.sub(r'\s{2,}', ' ', content)
        cleaned = content.strip()
        return cleaned[:800] + '...' if len(cleaned) > 800 else cleaned

    async def close(self):
        await self.web_search.close()

